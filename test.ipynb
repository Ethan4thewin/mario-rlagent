{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "import random, datetime, os\n",
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Gym is an OpenAI toolkit for RL\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "from gym.wrappers import FrameStack\n",
    "\n",
    "# NES Emulator for OpenAI Gym\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "# Super Mario environment for OpenAI Gym\n",
    "import gym_super_mario_bros\n",
    "\n",
    "from tensordict import TensorDict\n",
    "from torchrl.data import TensorDictReplayBuffer, LazyMemmapStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ethan\\miniconda3\\envs\\torch-rl\\lib\\site-packages\\gym\\envs\\registration.py:555: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\Ethan\\miniconda3\\envs\\torch-rl\\lib\\site-packages\\gym\\envs\\registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 256, 3),\n",
      " 0.0,\n",
      " False,\n",
      " {'coins': 0, 'flag_get': False, 'life': 2, 'score': 0, 'stage': 1, 'status': 'small', 'time': 400, 'world': 1, 'x_pos': 40, 'y_pos': 79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ethan\\miniconda3\\envs\\torch-rl\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "# Initialize Super Mario environment (in v0.26 change render mode to 'human' to see results on the screen)\n",
    "if gym.__version__ < '0.26':\n",
    "    env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\", new_step_api=True)\n",
    "else:\n",
    "    env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\", render_mode='rgb', apply_api_compatibility=True)\n",
    "\n",
    "# Limit the action-space to\n",
    "#   0. walk right\n",
    "#   1. jump right\n",
    "env = JoypadSpace(env, [[\"right\"], [\"right\", \"A\"]])\n",
    "\n",
    "env.reset()\n",
    "next_state, reward, done, trunc, info = env.step(action=0)\n",
    "print(f\"{next_state.shape},\\n {reward},\\n {done},\\n {info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipFrame(gym.Wrapper):\n",
    "    def __init__(self, env, skip):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, and sum reward\"\"\"\n",
    "        total_reward = 0.0\n",
    "        for i in range(self._skip):\n",
    "            # Accumulate reward and repeat the same action\n",
    "            obs, reward, done, trunk, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, trunk, info\n",
    "\n",
    "\n",
    "class GrayScaleObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape[:2]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def permute_orientation(self, observation):\n",
    "        # permute [H, W, C] array to [C, H, W] tensor\n",
    "        observation = np.transpose(observation, (2, 0, 1))\n",
    "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
    "        return observation\n",
    "\n",
    "    def observation(self, observation):\n",
    "        observation = self.permute_orientation(observation)\n",
    "        transform = T.Grayscale()\n",
    "        observation = transform(observation)\n",
    "        return observation\n",
    "\n",
    "\n",
    "class ResizeObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env, shape):\n",
    "        super().__init__(env)\n",
    "        if isinstance(shape, int):\n",
    "            self.shape = (shape, shape)\n",
    "        else:\n",
    "            self.shape = tuple(shape)\n",
    "\n",
    "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
    "        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        transforms = T.Compose(\n",
    "            [T.Resize(self.shape, antialias=True), T.Normalize(0, 255)]\n",
    "        )\n",
    "        observation = transforms(observation).squeeze(0)\n",
    "        return observation\n",
    "\n",
    "\n",
    "# Apply Wrappers to environment\n",
    "env = SkipFrame(env, skip=4)\n",
    "env = GrayScaleObservation(env)\n",
    "env = ResizeObservation(env, shape=84)\n",
    "if gym.__version__ < '0.26':\n",
    "    env = FrameStack(env, num_stack=4, new_step_api=True)\n",
    "else:\n",
    "    env = FrameStack(env, num_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleReplayBuffer:\n",
    "    \"\"\"A simple replay buffer implementation using deque with explicit GPU transfer\"\"\"\n",
    "    def __init__(self, capacity, device):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "        self.device = device\n",
    "\n",
    "    def push(self, state, next_state, action, reward, done):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        # Store as numpy arrays to save CPU memory\n",
    "        state = state[0].__array__() if isinstance(state, tuple) else state.__array__()\n",
    "        next_state = next_state[0].__array__() if isinstance(next_state, tuple) else next_state.__array__()\n",
    "        self.buffer.append((state, next_state, action, reward, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of transitions and move them to GPU immediately\"\"\"\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "        \n",
    "        # Batch states and convert to tensors on GPU directly\n",
    "        batch = [self.buffer[idx] for idx in indices]\n",
    "        state, next_state, action, reward, done = zip(*batch)\n",
    "\n",
    "        # Convert and move to GPU in a single operation\n",
    "        state = torch.stack([torch.from_numpy(s) for s in state]).float().to(self.device)\n",
    "        next_state = torch.stack([torch.from_numpy(s) for s in next_state]).float().to(self.device)\n",
    "        action = torch.tensor(action, dtype=torch.long, device=self.device)\n",
    "        reward = torch.tensor(reward, dtype=torch.float, device=self.device)\n",
    "        done = torch.tensor(done, dtype=torch.float, device=self.device)\n",
    "        \n",
    "        return state, next_state, action, reward, done\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario:\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.device = \"cuda\"\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f\"Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "        else:\n",
    "            print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "        # Mario's DNN to predict the most optimal action - we implement this in the Learn section\n",
    "        self.net = MarioNet(self.state_dim, self.action_dim).float().to(device=self.device)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"Memory Allocated after model creation: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "\n",
    "        self.exploration_rate = 1\n",
    "        self.exploration_rate_decay = 0.99995\n",
    "        self.exploration_rate_min = 0.1\n",
    "        self.curr_step = 0\n",
    "\n",
    "        self.save_every = 5e5  # no. of experiences between saving Mario Net\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"Initial GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "    Given a state, choose an epsilon-greedy action and update value of step.\n",
    "\n",
    "    Inputs:\n",
    "    state(``LazyFrame``): A single observation of the current state, dimension is (state_dim)\n",
    "    Outputs:\n",
    "    ``action_idx`` (``int``): An integer representing which action Mario will perform\n",
    "    \"\"\"\n",
    "        # EXPLORE\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            action_idx = np.random.randint(self.action_dim)\n",
    "\n",
    "        # EXPLOIT\n",
    "        else:\n",
    "            state = state[0].__array__() if isinstance(state, tuple) else state.__array__()\n",
    "            state = torch.tensor(state, device=self.device).unsqueeze(0)\n",
    "            action_values = self.net(state, model=\"online\")\n",
    "            action_idx = torch.argmax(action_values, axis=1).item()\n",
    "\n",
    "        # decrease exploration_rate\n",
    "        self.exploration_rate *= self.exploration_rate_decay\n",
    "        self.exploration_rate = max(self.exploration_rate_min, self.exploration_rate)\n",
    "\n",
    "        # increment step\n",
    "        self.curr_step += 1\n",
    "        return action_idx\n",
    "\n",
    "class Mario(Mario):  # subclassing for continuity\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.memory = SimpleReplayBuffer(50000, self.device)\n",
    "        self.batch_size = 128\n",
    "\n",
    "    def cache(self, state, next_state, action, reward, done):\n",
    "        \"\"\"\n",
    "        Store the experience to self.memory (replay buffer)\n",
    "\n",
    "        Inputs:\n",
    "        state (``LazyFrame``),\n",
    "        next_state (``LazyFrame``),\n",
    "        action (``int``),\n",
    "        reward (``float``),\n",
    "        done(``bool``))\n",
    "        \"\"\"\n",
    "        def first_if_tuple(x):\n",
    "            return x[0] if isinstance(x, tuple) else x\n",
    "        state = first_if_tuple(state).__array__()\n",
    "        next_state = first_if_tuple(next_state).__array__()\n",
    "\n",
    "        state = torch.tensor(state)\n",
    "        next_state = torch.tensor(next_state)\n",
    "        action = torch.tensor([action])\n",
    "        reward = torch.tensor([reward])\n",
    "        done = torch.tensor([done])\n",
    "\n",
    "        # self.memory.append((state, next_state, action, reward, done,))\n",
    "        self.memory.push(state, next_state, action, reward, done)\n",
    "\n",
    "    def recall(self):\n",
    "        \"\"\"\n",
    "        Retrieve a batch of experiences from memory\n",
    "        \"\"\"\n",
    "        return self.memory.sample(self.batch_size)\n",
    "\n",
    "class MarioNet(nn.Module):\n",
    "    \"\"\"mini CNN structure\n",
    "  input -> (conv2d + relu) x 3 -> flatten -> (dense + relu) x 2 -> output\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        c, h, w = input_dim\n",
    "\n",
    "        if h != 84:\n",
    "            raise ValueError(f\"Expecting input height: 84, got: {h}\")\n",
    "        if w != 84:\n",
    "            raise ValueError(f\"Expecting input width: 84, got: {w}\")\n",
    "\n",
    "        self.online = self.__build_cnn(c, output_dim)\n",
    "\n",
    "        self.target = self.__build_cnn(c, output_dim)\n",
    "        self.target.load_state_dict(self.online.state_dict())\n",
    "\n",
    "        # Q_target parameters are frozen.\n",
    "        for p in self.target.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def forward(self, input, model):\n",
    "        if model == \"online\":\n",
    "            return self.online(input)\n",
    "        elif model == \"target\":\n",
    "            return self.target(input)\n",
    "\n",
    "    def __build_cnn(self, c, output_dim):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_dim),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ethan\\AppData\\Local\\Temp\\ipykernel_16328\\3934922352.py:6: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast()\n",
      "C:\\Users\\Ethan\\AppData\\Local\\Temp\\ipykernel_16328\\3934922352.py:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast()\n"
     ]
    }
   ],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.gamma = 0.95\n",
    "\n",
    "    @torch.cuda.amp.autocast()\n",
    "    def td_estimate(self, state, action):\n",
    "        current_Q = self.net(state, model=\"online\")[\n",
    "            np.arange(0, self.batch_size), action\n",
    "        ]  # Q_online(s,a)\n",
    "        return current_Q\n",
    "\n",
    "    @torch.cuda.amp.autocast()\n",
    "    @torch.no_grad()\n",
    "    def td_target(self, reward, next_state, done):\n",
    "        next_state_Q = self.net(next_state, model=\"online\")\n",
    "        best_action = torch.argmax(next_state_Q, axis=1)\n",
    "        next_Q = self.net(next_state, model=\"target\")[\n",
    "            np.arange(0, self.batch_size), best_action\n",
    "        ]\n",
    "        return (reward + (1 - done.float()) * self.gamma * next_Q).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=0.0005)\n",
    "        self.loss_fn = torch.nn.SmoothL1Loss()\n",
    "\n",
    "    def update_Q_online(self, td_estimate, td_target):\n",
    "        loss = self.loss_fn(td_estimate, td_target)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def sync_Q_target(self):\n",
    "        self.net.target.load_state_dict(self.net.online.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def save(self):\n",
    "        save_path = (\n",
    "            self.save_dir / f\"mario_net_{int(self.curr_step // self.save_every)}.chkpt\"\n",
    "        )\n",
    "        torch.save(\n",
    "            dict(model=self.net.state_dict(), exploration_rate=self.exploration_rate),\n",
    "            save_path,\n",
    "        )\n",
    "        print(f\"MarioNet saved to {save_path} at step {self.curr_step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mario(Mario):\n",
    "    def __init__(self, state_dim, action_dim, save_dir):\n",
    "        super().__init__(state_dim, action_dim, save_dir)\n",
    "        self.burnin = 5000  # min. experiences before training\n",
    "        self.learn_every = 2  # no. of experiences between updates to Q_online\n",
    "        self.sync_every = 5000  # no. of experiences between Q_target & Q_online sync\n",
    "\n",
    "    def learn(self):\n",
    "        if self.curr_step % self.sync_every == 0:\n",
    "            self.sync_Q_target()\n",
    "\n",
    "        if self.curr_step % self.save_every == 0:\n",
    "            self.save()\n",
    "\n",
    "        if self.curr_step < self.burnin:\n",
    "            return None, None\n",
    "\n",
    "        if self.curr_step % self.learn_every != 0:\n",
    "            return None, None\n",
    "\n",
    "        # Sample from memory\n",
    "        state, next_state, action, reward, done = self.recall()\n",
    "\n",
    "        # Get TD Estimate\n",
    "        td_est = self.td_estimate(state, action)\n",
    "\n",
    "        # Get TD Target\n",
    "        td_tgt = self.td_target(reward, next_state, done)\n",
    "\n",
    "        # Backpropagate loss through Q_online\n",
    "        loss = self.update_Q_online(td_est, td_tgt)\n",
    "\n",
    "        # Print training stats periodically\n",
    "        if self.curr_step % 1000 == 0:\n",
    "            print(f\"Step: {self.curr_step} \"\n",
    "                  f\"TD Est Mean: {td_est.mean().item():.4f}, \"\n",
    "                  f\"Exploration Rate: {self.exploration_rate:.4f}\")\n",
    "\n",
    "        if self.curr_step % 1000 == 0 and torch.cuda.is_available():\n",
    "            print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "\n",
    "        return (td_est.mean().item(), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricLogger:\n",
    "    def __init__(self, save_dir):\n",
    "        self.save_log = save_dir / \"log\"\n",
    "        with open(self.save_log, \"w\") as f:\n",
    "            f.write(\n",
    "                f\"{'Episode':>8}{'Step':>8}{'Epsilon':>10}{'MeanReward':>15}\"\n",
    "                f\"{'MeanLength':>15}{'MeanLoss':>15}{'MeanQValue':>15}\"\n",
    "                f\"{'TimeDelta':>15}{'Time':>20}\\n\"\n",
    "            )\n",
    "        self.ep_rewards_plot = save_dir / \"reward_plot.jpg\"\n",
    "        self.ep_lengths_plot = save_dir / \"length_plot.jpg\"\n",
    "        self.ep_avg_losses_plot = save_dir / \"loss_plot.jpg\"\n",
    "        self.ep_avg_qs_plot = save_dir / \"q_plot.jpg\"\n",
    "\n",
    "        # History metrics\n",
    "        self.ep_rewards = []\n",
    "        self.ep_lengths = []\n",
    "        self.ep_avg_losses = []\n",
    "        self.ep_avg_qs = []\n",
    "\n",
    "        # Moving averages, added for every call to record()\n",
    "        self.moving_avg_ep_rewards = []\n",
    "        self.moving_avg_ep_lengths = []\n",
    "        self.moving_avg_ep_avg_losses = []\n",
    "        self.moving_avg_ep_avg_qs = []\n",
    "\n",
    "        # Current episode metric\n",
    "        self.init_episode()\n",
    "\n",
    "        # Timing\n",
    "        self.record_time = time.time()\n",
    "\n",
    "    def log_step(self, reward, loss, q):\n",
    "        self.curr_ep_reward += reward\n",
    "        self.curr_ep_length += 1\n",
    "        if loss:\n",
    "            self.curr_ep_loss += loss\n",
    "            self.curr_ep_q += q\n",
    "            self.curr_ep_loss_length += 1\n",
    "\n",
    "    def log_episode(self):\n",
    "        \"Mark end of episode\"\n",
    "        self.ep_rewards.append(self.curr_ep_reward)\n",
    "        self.ep_lengths.append(self.curr_ep_length)\n",
    "        if self.curr_ep_loss_length == 0:\n",
    "            ep_avg_loss = 0\n",
    "            ep_avg_q = 0\n",
    "        else:\n",
    "            ep_avg_loss = np.round(self.curr_ep_loss / self.curr_ep_loss_length, 5)\n",
    "            ep_avg_q = np.round(self.curr_ep_q / self.curr_ep_loss_length, 5)\n",
    "        self.ep_avg_losses.append(ep_avg_loss)\n",
    "        self.ep_avg_qs.append(ep_avg_q)\n",
    "\n",
    "        self.init_episode()\n",
    "\n",
    "    def init_episode(self):\n",
    "        self.curr_ep_reward = 0.0\n",
    "        self.curr_ep_length = 0\n",
    "        self.curr_ep_loss = 0.0\n",
    "        self.curr_ep_q = 0.0\n",
    "        self.curr_ep_loss_length = 0\n",
    "\n",
    "    def record(self, episode, epsilon, step):\n",
    "        mean_ep_reward = np.round(np.mean(self.ep_rewards[-100:]), 3)\n",
    "        mean_ep_length = np.round(np.mean(self.ep_lengths[-100:]), 3)\n",
    "        mean_ep_loss = np.round(np.mean(self.ep_avg_losses[-100:]), 3)\n",
    "        mean_ep_q = np.round(np.mean(self.ep_avg_qs[-100:]), 3)\n",
    "        self.moving_avg_ep_rewards.append(mean_ep_reward)\n",
    "        self.moving_avg_ep_lengths.append(mean_ep_length)\n",
    "        self.moving_avg_ep_avg_losses.append(mean_ep_loss)\n",
    "        self.moving_avg_ep_avg_qs.append(mean_ep_q)\n",
    "\n",
    "        last_record_time = self.record_time\n",
    "        self.record_time = time.time()\n",
    "        time_since_last_record = np.round(self.record_time - last_record_time, 3)\n",
    "\n",
    "        print(\n",
    "            f\"Episode {episode} - \"\n",
    "            f\"Step {step} - \"\n",
    "            f\"Epsilon {epsilon} - \"\n",
    "            f\"Mean Reward {mean_ep_reward} - \"\n",
    "            f\"Mean Length {mean_ep_length} - \"\n",
    "            f\"Mean Loss {mean_ep_loss} - \"\n",
    "            f\"Mean Q Value {mean_ep_q} - \"\n",
    "            f\"Time Delta {time_since_last_record} - \"\n",
    "            f\"Time {datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\"\n",
    "        )\n",
    "\n",
    "        with open(self.save_log, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"{episode:8d}{step:8d}{epsilon:10.3f}\"\n",
    "                f\"{mean_ep_reward:15.3f}{mean_ep_length:15.3f}{mean_ep_loss:15.3f}{mean_ep_q:15.3f}\"\n",
    "                f\"{time_since_last_record:15.3f}\"\n",
    "                f\"{datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'):>20}\\n\"\n",
    "            )\n",
    "\n",
    "        for metric in [\"ep_lengths\", \"ep_avg_losses\", \"ep_avg_qs\", \"ep_rewards\"]:\n",
    "            plt.clf()\n",
    "            plt.plot(getattr(self, f\"moving_avg_{metric}\"), label=f\"moving_avg_{metric}\")\n",
    "            plt.legend()\n",
    "            plt.savefig(getattr(self, f\"{metric}_plot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(f\"Using CUDA: {use_cuda}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3060 Ti\n",
      "Memory Allocated: 102.00 MB\n",
      "Memory Allocated after model creation: 114.85 MB\n",
      "Initial GPU Memory Allocated: 114.85 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 114.85 MB\n",
      "Memory Cached: 136.00 MB\n",
      "Episode 0 - Step 403 - Epsilon 0.98005116081509 - Mean Reward 992.0 - Mean Length 403.0 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 3.014 - Time 2024-11-07T20:57:54\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 114.85 MB\n",
      "Memory Cached: 136.00 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 114.85 MB\n",
      "Memory Cached: 136.00 MB\n",
      "Episode 20 - Step 3253 - Epsilon 0.8498851414063989 - Mean Reward 632.905 - Mean Length 154.905 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 22.035 - Time 2024-11-07T20:58:16\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 89.14 MB\n",
      "Memory Cached: 136.00 MB\n",
      "Step: 5000 TD Est Mean: 0.0189, Exploration Rate: 0.7788\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 6000 TD Est Mean: 4.9414, Exploration Rate: 0.7408\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 7000 TD Est Mean: 4.5273, Exploration Rate: 0.7047\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Episode 40 - Step 7250 - Epsilon 0.6959280065922901 - Mean Reward 691.78 - Mean Length 176.829 - Mean Loss 0.317 - Mean Q Value 1.227 - Time Delta 51.715 - Time 2024-11-07T20:59:08\n",
      "Step: 8000 TD Est Mean: 4.1055, Exploration Rate: 0.6703\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 9000 TD Est Mean: 3.7656, Exploration Rate: 0.6376\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 10000 TD Est Mean: 3.8672, Exploration Rate: 0.6065\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 11000 TD Est Mean: 7.8633, Exploration Rate: 0.5769\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 60 - Step 11597 - Epsilon 0.55997423976358 - Mean Reward 696.377 - Mean Length 190.115 - Mean Loss 0.356 - Mean Q Value 2.522 - Time Delta 75.582 - Time 2024-11-07T21:00:23\n",
      "Step: 12000 TD Est Mean: 7.4766, Exploration Rate: 0.5488\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 13000 TD Est Mean: 7.4688, Exploration Rate: 0.5220\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 14000 TD Est Mean: 6.3828, Exploration Rate: 0.4966\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 80 - Step 14883 - Epsilon 0.4751291560803472 - Mean Reward 669.593 - Mean Length 183.741 - Mean Loss 0.377 - Mean Q Value 3.715 - Time Delta 57.246 - Time 2024-11-07T21:01:21\n",
      "Step: 15000 TD Est Mean: 7.6719, Exploration Rate: 0.4724\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 16000 TD Est Mean: 11.2656, Exploration Rate: 0.4493\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 17000 TD Est Mean: 10.2109, Exploration Rate: 0.4274\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 18000 TD Est Mean: 11.0234, Exploration Rate: 0.4066\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 19000 TD Est Mean: 9.6719, Exploration Rate: 0.3867\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 100 - Step 19249 - Epsilon 0.38194675609057477 - Mean Reward 677.67 - Mean Length 188.46 - Mean Loss 0.414 - Mean Q Value 5.13 - Time Delta 77.475 - Time 2024-11-07T21:02:38\n",
      "Step: 20000 TD Est Mean: 9.8984, Exploration Rate: 0.3679\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 21000 TD Est Mean: 14.6016, Exploration Rate: 0.3499\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 22000 TD Est Mean: 14.2422, Exploration Rate: 0.3329\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 120 - Step 22970 - Epsilon 0.31710297567428364 - Mean Reward 707.38 - Mean Length 197.17 - Mean Loss 0.551 - Mean Q Value 7.811 - Time Delta 66.016 - Time 2024-11-07T21:03:44\n",
      "Step: 23000 TD Est Mean: 13.4844, Exploration Rate: 0.3166\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 24000 TD Est Mean: 15.8906, Exploration Rate: 0.3012\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 25000 TD Est Mean: 14.7266, Exploration Rate: 0.2865\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 140 - Step 25561 - Epsilon 0.2785711010175053 - Mean Reward 671.01 - Mean Length 183.11 - Mean Loss 0.555 - Mean Q Value 10.316 - Time Delta 47.313 - Time 2024-11-07T21:04:31\n",
      "Step: 26000 TD Est Mean: 16.0469, Exploration Rate: 0.2725\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 27000 TD Est Mean: 17.6094, Exploration Rate: 0.2592\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 28000 TD Est Mean: 17.6094, Exploration Rate: 0.2466\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 160 - Step 28209 - Epsilon 0.2440248383324753 - Mean Reward 648.28 - Mean Length 166.12 - Mean Loss 0.611 - Mean Q Value 12.789 - Time Delta 47.93 - Time 2024-11-07T21:05:19\n",
      "Step: 29000 TD Est Mean: 16.1094, Exploration Rate: 0.2346\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 30000 TD Est Mean: 17.2969, Exploration Rate: 0.2231\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 31000 TD Est Mean: 19.5938, Exploration Rate: 0.2122\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 180 - Step 31492 - Epsilon 0.20708222004128307 - Mean Reward 676.41 - Mean Length 166.09 - Mean Loss 0.677 - Mean Q Value 15.198 - Time Delta 67.329 - Time 2024-11-07T21:06:27\n",
      "Step: 32000 TD Est Mean: 21.2344, Exploration Rate: 0.2019\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 33000 TD Est Mean: 20.7969, Exploration Rate: 0.1920\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 34000 TD Est Mean: 20.0938, Exploration Rate: 0.1827\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 200 - Step 34303 - Epsilon 0.17992901262577693 - Mean Reward 665.49 - Mean Length 150.54 - Mean Loss 0.727 - Mean Q Value 17.389 - Time Delta 54.707 - Time 2024-11-07T21:07:21\n",
      "Step: 35000 TD Est Mean: 20.8906, Exploration Rate: 0.1738\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 36000 TD Est Mean: 24.0469, Exploration Rate: 0.1653\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 37000 TD Est Mean: 25.4688, Exploration Rate: 0.1572\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Episode 220 - Step 37099 - Epsilon 0.15645350977164385 - Mean Reward 633.89 - Mean Length 141.29 - Mean Loss 0.768 - Mean Q Value 19.472 - Time Delta 56.766 - Time 2024-11-07T21:08:18\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 38000 TD Est Mean: 26.0781, Exploration Rate: 0.1496\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 39000 TD Est Mean: 25.6406, Exploration Rate: 0.1423\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 240 - Step 39886 - Epsilon 0.1361021109495484 - Mean Reward 654.17 - Mean Length 143.25 - Mean Loss 0.797 - Mean Q Value 21.409 - Time Delta 60.081 - Time 2024-11-07T21:09:18\n",
      "Step: 40000 TD Est Mean: 26.0625, Exploration Rate: 0.1353\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 41000 TD Est Mean: 27.8594, Exploration Rate: 0.1287\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 260 - Step 41847 - Epsilon 0.1233903575326954 - Mean Reward 635.98 - Mean Length 136.38 - Mean Loss 0.873 - Mean Q Value 23.535 - Time Delta 39.259 - Time 2024-11-07T21:09:57\n",
      "Step: 42000 TD Est Mean: 29.5312, Exploration Rate: 0.1224\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 43000 TD Est Mean: 27.8906, Exploration Rate: 0.1165\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 44000 TD Est Mean: 28.8594, Exploration Rate: 0.1108\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 280 - Step 44174 - Epsilon 0.10983728678582225 - Mean Reward 599.69 - Mean Length 126.82 - Mean Loss 0.919 - Mean Q Value 25.403 - Time Delta 42.185 - Time 2024-11-07T21:10:40\n",
      "Step: 45000 TD Est Mean: 26.3281, Exploration Rate: 0.1054\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 46000 TD Est Mean: 33.9375, Exploration Rate: 0.1003\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 300 - Step 46804 - Epsilon 0.1 - Mean Reward 594.24 - Mean Length 125.01 - Mean Loss 0.993 - Mean Q Value 27.26 - Time Delta 48.838 - Time 2024-11-07T21:11:28\n",
      "Step: 47000 TD Est Mean: 29.9531, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 48000 TD Est Mean: 31.1875, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 49000 TD Est Mean: 32.8125, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 320 - Step 49642 - Epsilon 0.1 - Mean Reward 607.46 - Mean Length 125.43 - Mean Loss 1.045 - Mean Q Value 28.922 - Time Delta 51.322 - Time 2024-11-07T21:12:20\n",
      "Step: 50000 TD Est Mean: 28.5312, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 51000 TD Est Mean: 33.3125, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 340 - Step 51327 - Epsilon 0.1 - Mean Reward 554.94 - Mean Length 114.41 - Mean Loss 1.168 - Mean Q Value 30.921 - Time Delta 31.658 - Time 2024-11-07T21:12:51\n",
      "Step: 52000 TD Est Mean: 33.8438, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 53000 TD Est Mean: 37.2188, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 360 - Step 53374 - Epsilon 0.1 - Mean Reward 557.07 - Mean Length 115.27 - Mean Loss 1.22 - Mean Q Value 32.321 - Time Delta 37.497 - Time 2024-11-07T21:13:29\n",
      "Step: 54000 TD Est Mean: 32.1562, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 55000 TD Est Mean: 34.4062, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 56000 TD Est Mean: 38.2188, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 380 - Step 56560 - Epsilon 0.1 - Mean Reward 595.58 - Mean Length 123.86 - Mean Loss 1.296 - Mean Q Value 33.917 - Time Delta 58.418 - Time 2024-11-07T21:14:27\n",
      "Step: 57000 TD Est Mean: 41.6875, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 58000 TD Est Mean: 38.2188, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 59000 TD Est Mean: 39.5938, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 400 - Step 59439 - Epsilon 0.1 - Mean Reward 606.84 - Mean Length 126.35 - Mean Loss 1.343 - Mean Q Value 35.497 - Time Delta 53.626 - Time 2024-11-07T21:15:21\n",
      "Step: 60000 TD Est Mean: 38.3750, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 61000 TD Est Mean: 42.7812, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 62000 TD Est Mean: 40.3750, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 420 - Step 62232 - Epsilon 0.1 - Mean Reward 603.58 - Mean Length 125.9 - Mean Loss 1.436 - Mean Q Value 37.274 - Time Delta 51.588 - Time 2024-11-07T21:16:13\n",
      "Step: 63000 TD Est Mean: 41.9062, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 64000 TD Est Mean: 42.8750, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 440 - Step 64997 - Epsilon 0.1 - Mean Reward 663.19 - Mean Length 136.7 - Mean Loss 1.447 - Mean Q Value 38.765 - Time Delta 52.622 - Time 2024-11-07T21:17:05\n",
      "Step: 65000 TD Est Mean: 43.7500, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 66000 TD Est Mean: 45.2812, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 67000 TD Est Mean: 46.8125, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 460 - Step 67376 - Epsilon 0.1 - Mean Reward 685.09 - Mean Length 140.02 - Mean Loss 1.533 - Mean Q Value 40.844 - Time Delta 44.341 - Time 2024-11-07T21:17:50\n",
      "Step: 68000 TD Est Mean: 45.1562, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 69000 TD Est Mean: 44.7500, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 480 - Step 69488 - Epsilon 0.1 - Mean Reward 655.17 - Mean Length 129.28 - Mean Loss 1.591 - Mean Q Value 42.766 - Time Delta 40.026 - Time 2024-11-07T21:18:30\n",
      "Step: 70000 TD Est Mean: 46.7188, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 71000 TD Est Mean: 43.4062, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 72000 TD Est Mean: 48.6562, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 500 - Step 72180 - Epsilon 0.1 - Mean Reward 659.2 - Mean Length 127.41 - Mean Loss 1.689 - Mean Q Value 44.807 - Time Delta 50.626 - Time 2024-11-07T21:19:20\n",
      "Step: 73000 TD Est Mean: 48.2188, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 74000 TD Est Mean: 48.0938, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 75000 TD Est Mean: 51.2188, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Episode 520 - Step 75039 - Epsilon 0.1 - Mean Reward 678.28 - Mean Length 128.07 - Mean Loss 1.744 - Mean Q Value 46.659 - Time Delta 56.503 - Time 2024-11-07T21:20:17\n",
      "Step: 76000 TD Est Mean: 56.4688, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 77000 TD Est Mean: 55.9062, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 540 - Step 77970 - Epsilon 0.1 - Mean Reward 685.17 - Mean Length 129.73 - Mean Loss 1.866 - Mean Q Value 48.83 - Time Delta 57.704 - Time 2024-11-07T21:21:14\n",
      "Step: 78000 TD Est Mean: 54.8438, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 79000 TD Est Mean: 54.3125, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 560 - Step 79913 - Epsilon 0.1 - Mean Reward 672.31 - Mean Length 125.37 - Mean Loss 1.882 - Mean Q Value 50.392 - Time Delta 39.134 - Time 2024-11-07T21:21:54\n",
      "Step: 80000 TD Est Mean: 58.2500, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 81000 TD Est Mean: 57.7500, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 82000 TD Est Mean: 59.4375, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 83000 TD Est Mean: 63.3125, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 580 - Step 83398 - Epsilon 0.1 - Mean Reward 738.46 - Mean Length 139.1 - Mean Loss 1.982 - Mean Q Value 52.215 - Time Delta 75.978 - Time 2024-11-07T21:23:10\n",
      "Step: 84000 TD Est Mean: 53.5938, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 85000 TD Est Mean: 52.9688, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 86000 TD Est Mean: 51.6562, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 600 - Step 86613 - Epsilon 0.1 - Mean Reward 762.49 - Mean Length 144.33 - Mean Loss 2.043 - Mean Q Value 53.801 - Time Delta 85.671 - Time 2024-11-07T21:24:35\n",
      "Step: 87000 TD Est Mean: 62.7188, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 88000 TD Est Mean: 58.2188, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 89000 TD Est Mean: 57.0938, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 90000 TD Est Mean: 61.9062, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 620 - Step 90146 - Epsilon 0.1 - Mean Reward 807.95 - Mean Length 151.07 - Mean Loss 2.11 - Mean Q Value 55.466 - Time Delta 100.484 - Time 2024-11-07T21:26:16\n",
      "Step: 91000 TD Est Mean: 57.9062, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 92000 TD Est Mean: 62.6250, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 93000 TD Est Mean: 59.6562, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Episode 640 - Step 93136 - Epsilon 0.1 - Mean Reward 819.04 - Mean Length 151.66 - Mean Loss 2.174 - Mean Q Value 57.027 - Time Delta 94.054 - Time 2024-11-07T21:27:50\n",
      "Step: 94000 TD Est Mean: 64.3750, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 95000 TD Est Mean: 61.7812, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 660 - Step 95510 - Epsilon 0.1 - Mean Reward 838.79 - Mean Length 155.97 - Mean Loss 2.282 - Mean Q Value 58.647 - Time Delta 73.949 - Time 2024-11-07T21:29:04\n",
      "Step: 96000 TD Est Mean: 60.7188, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 97000 TD Est Mean: 62.5938, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 98000 TD Est Mean: 67.1250, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Episode 680 - Step 98009 - Epsilon 0.1 - Mean Reward 788.54 - Mean Length 146.11 - Mean Loss 2.362 - Mean Q Value 60.143 - Time Delta 71.34 - Time 2024-11-07T21:30:15\n",
      "Step: 99000 TD Est Mean: 65.5625, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 100000 TD Est Mean: 63.6250, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 101000 TD Est Mean: 65.1875, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Episode 700 - Step 101081 - Epsilon 0.1 - Mean Reward 785.4 - Mean Length 144.68 - Mean Loss 2.424 - Mean Q Value 61.549 - Time Delta 81.076 - Time 2024-11-07T21:31:36\n",
      "Step: 102000 TD Est Mean: 67.6250, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 103000 TD Est Mean: 64.1875, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 720 - Step 103787 - Epsilon 0.1 - Mean Reward 743.65 - Mean Length 136.41 - Mean Loss 2.505 - Mean Q Value 62.89 - Time Delta 71.895 - Time 2024-11-07T21:32:48\n",
      "Step: 104000 TD Est Mean: 66.5625, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 105000 TD Est Mean: 65.7500, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 106000 TD Est Mean: 66.3750, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 740 - Step 106469 - Epsilon 0.1 - Mean Reward 725.89 - Mean Length 133.33 - Mean Loss 2.538 - Mean Q Value 64.057 - Time Delta 88.183 - Time 2024-11-07T21:34:16\n",
      "Step: 107000 TD Est Mean: 65.5625, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 108000 TD Est Mean: 71.2500, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 109000 TD Est Mean: 67.8750, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 760 - Step 109384 - Epsilon 0.1 - Mean Reward 746.88 - Mean Length 138.74 - Mean Loss 2.568 - Mean Q Value 65.337 - Time Delta 68.812 - Time 2024-11-07T21:35:25\n",
      "Step: 110000 TD Est Mean: 68.1875, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 111000 TD Est Mean: 67.9375, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 112000 TD Est Mean: 68.9375, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Episode 780 - Step 112122 - Epsilon 0.1 - Mean Reward 765.39 - Mean Length 141.13 - Mean Loss 2.623 - Mean Q Value 66.677 - Time Delta 51.378 - Time 2024-11-07T21:36:16\n",
      "Step: 113000 TD Est Mean: 75.0000, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 114000 TD Est Mean: 73.7500, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 115000 TD Est Mean: 70.4375, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 800 - Step 115761 - Epsilon 0.1 - Mean Reward 780.79 - Mean Length 146.8 - Mean Loss 2.69 - Mean Q Value 68.0 - Time Delta 65.585 - Time 2024-11-07T21:37:22\n",
      "Step: 116000 TD Est Mean: 65.6250, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 117000 TD Est Mean: 75.4375, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 118000 TD Est Mean: 73.1875, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 820 - Step 118258 - Epsilon 0.1 - Mean Reward 768.32 - Mean Length 144.71 - Mean Loss 2.747 - Mean Q Value 69.362 - Time Delta 46.036 - Time 2024-11-07T21:38:08\n",
      "Step: 119000 TD Est Mean: 76.0625, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 120000 TD Est Mean: 72.3125, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 121000 TD Est Mean: 76.7500, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 840 - Step 121670 - Epsilon 0.1 - Mean Reward 794.05 - Mean Length 152.01 - Mean Loss 2.816 - Mean Q Value 70.628 - Time Delta 62.147 - Time 2024-11-07T21:39:10\n",
      "Step: 122000 TD Est Mean: 75.5625, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 123000 TD Est Mean: 71.3125, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 124000 TD Est Mean: 76.2500, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 860 - Step 124362 - Epsilon 0.1 - Mean Reward 781.77 - Mean Length 149.78 - Mean Loss 2.862 - Mean Q Value 71.783 - Time Delta 49.303 - Time 2024-11-07T21:39:59\n",
      "Step: 125000 TD Est Mean: 72.2500, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 126000 TD Est Mean: 74.6250, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 127000 TD Est Mean: 75.1250, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 880 - Step 127527 - Epsilon 0.1 - Mean Reward 797.51 - Mean Length 154.05 - Mean Loss 2.888 - Mean Q Value 72.766 - Time Delta 58.05 - Time 2024-11-07T21:40:57\n",
      "Step: 128000 TD Est Mean: 69.5000, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 129000 TD Est Mean: 72.5000, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 130000 TD Est Mean: 70.0625, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 900 - Step 130908 - Epsilon 0.1 - Mean Reward 795.46 - Mean Length 151.47 - Mean Loss 2.93 - Mean Q Value 73.731 - Time Delta 61.29 - Time 2024-11-07T21:41:59\n",
      "Step: 131000 TD Est Mean: 76.4375, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 132000 TD Est Mean: 75.1875, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 133000 TD Est Mean: 73.1875, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 134000 TD Est Mean: 74.6875, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 920 - Step 134689 - Epsilon 0.1 - Mean Reward 860.86 - Mean Length 164.31 - Mean Loss 2.958 - Mean Q Value 74.612 - Time Delta 69.128 - Time 2024-11-07T21:43:08\n",
      "Step: 135000 TD Est Mean: 80.8750, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 136000 TD Est Mean: 75.6250, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 137000 TD Est Mean: 82.5625, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 138000 TD Est Mean: 76.1250, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 940 - Step 138667 - Epsilon 0.1 - Mean Reward 889.48 - Mean Length 169.97 - Mean Loss 3.007 - Mean Q Value 75.501 - Time Delta 73.422 - Time 2024-11-07T21:44:21\n",
      "Step: 139000 TD Est Mean: 77.1875, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 140000 TD Est Mean: 77.2500, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 141000 TD Est Mean: 77.1250, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 960 - Step 141821 - Epsilon 0.1 - Mean Reward 915.61 - Mean Length 174.59 - Mean Loss 3.093 - Mean Q Value 76.33 - Time Delta 64.19 - Time 2024-11-07T21:45:25\n",
      "Step: 142000 TD Est Mean: 79.3125, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 143000 TD Est Mean: 72.8750, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 144000 TD Est Mean: 76.5625, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 145000 TD Est Mean: 80.5625, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Episode 980 - Step 145256 - Epsilon 0.1 - Mean Reward 921.33 - Mean Length 177.29 - Mean Loss 3.126 - Mean Q Value 76.999 - Time Delta 70.118 - Time 2024-11-07T21:46:36\n",
      "Step: 146000 TD Est Mean: 79.0625, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 147000 TD Est Mean: 77.8125, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "\n",
      "Current GPU utilization:\n",
      "Memory Allocated: 108.42 MB\n",
      "Memory Cached: 202.00 MB\n",
      "Step: 148000 TD Est Mean: 84.2500, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Step: 149000 TD Est Mean: 77.4375, Exploration Rate: 0.1000\n",
      "GPU Memory Allocated: 136.43 MB\n",
      "Episode 999 - Step 149185 - Epsilon 0.1 - Mean Reward 914.52 - Mean Length 183.17 - Mean Loss 3.175 - Mean Q Value 77.547 - Time Delta 98.528 - Time 2024-11-07T21:48:14\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def check_gpu_utilization():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"\\nCurrent GPU utilization:\")\n",
    "        print(f\"Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "        print(f\"Memory Cached: {torch.cuda.memory_reserved(0) / 1024**2:.2f} MB\")\n",
    "\n",
    "save_dir = Path(\"checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "save_dir.mkdir(parents=True)\n",
    "\n",
    "mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir)\n",
    "\n",
    "logger = MetricLogger(save_dir)\n",
    "\n",
    "episodes = 1000\n",
    "for e in range(episodes):\n",
    "\n",
    "    state = env.reset()\n",
    "    \n",
    "    if e % 10 == 0:\n",
    "        check_gpu_utilization()\n",
    "\n",
    "    # Play the game!\n",
    "    while True:\n",
    "\n",
    "        # Run agent on the state\n",
    "        action = mario.act(state)\n",
    "\n",
    "        # Agent performs action\n",
    "        next_state, reward, done, trunc, info = env.step(action)\n",
    "\n",
    "        # Remember\n",
    "        mario.cache(state, next_state, action, reward, done)\n",
    "\n",
    "        # Learn\n",
    "        q, loss = mario.learn()\n",
    "\n",
    "        # Logging\n",
    "        logger.log_step(reward, loss, q)\n",
    "\n",
    "        # Update state\n",
    "        state = next_state\n",
    "\n",
    "        # Check if end of game\n",
    "        if done or info[\"flag_get\"]:\n",
    "            break\n",
    "\n",
    "    logger.log_episode()\n",
    "\n",
    "    if (e % 20 == 0) or (e == episodes - 1):\n",
    "        logger.record(episode=e, epsilon=mario.exploration_rate, step=mario.curr_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
